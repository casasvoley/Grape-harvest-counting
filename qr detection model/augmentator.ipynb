{"cells":[{"cell_type":"code","source":["from google.colab import drive\n","\n","drive.mount('/content/gdrive/', force_remount=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"poeCA-m2Gypg","executionInfo":{"status":"ok","timestamp":1684596257956,"user_tz":-120,"elapsed":4198,"user":{"displayName":"Álvaro Casas Zan","userId":"12446977778724773210"}},"outputId":"a80b2794-e771-4968-9d76-278d7aba0e0a"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive/\n"]}]},{"cell_type":"code","execution_count":22,"metadata":{"id":"gT_kCNsTGcFF","executionInfo":{"status":"ok","timestamp":1684596260330,"user_tz":-120,"elapsed":431,"user":{"displayName":"Álvaro Casas Zan","userId":"12446977778724773210"}}},"outputs":[],"source":["import os\n","import cv2\n","import random\n","import numpy as np\n","import shutil\n","import albumentations as A\n","from albumentations.pytorch.transforms import ToTensorV2"]},{"cell_type":"code","execution_count":23,"metadata":{"id":"eUUmv2NqGcFH","executionInfo":{"status":"ok","timestamp":1684596262365,"user_tz":-120,"elapsed":1,"user":{"displayName":"Álvaro Casas Zan","userId":"12446977778724773210"}}},"outputs":[],"source":["def leer_anotaciones_yolo(anotacion_txt):\n","    with open(anotacion_txt, \"r\") as f:\n","        lineas = f.readlines()\n","    \n","    anotaciones = []\n","    for linea in lineas:\n","        anotaciones.append([float(i) for i in linea.strip().split(\" \")])\n","        \n","    return anotaciones"]},{"cell_type":"code","execution_count":24,"metadata":{"id":"8dShHI_uGcFH","executionInfo":{"status":"ok","timestamp":1684596263776,"user_tz":-120,"elapsed":1,"user":{"displayName":"Álvaro Casas Zan","userId":"12446977778724773210"}}},"outputs":[],"source":["def guardar_anotaciones_yolo(anotaciones, archivo_salida):\n","    with open(archivo_salida, \"w\") as f:\n","        for anotacion in anotaciones:\n","            linea = \" \".join(str(i) for i in anotacion)\n","            f.write(linea + \"\\n\")"]},{"cell_type":"code","execution_count":25,"metadata":{"id":"AyELx-gvGcFH","executionInfo":{"status":"ok","timestamp":1684596265471,"user_tz":-120,"elapsed":2,"user":{"displayName":"Álvaro Casas Zan","userId":"12446977778724773210"}}},"outputs":[],"source":["def aplicar_transformacion(img, anotaciones, transform):\n","    labels = [x[0] for x in anotaciones]\n","    bboxes = [x[1:] for x in anotaciones]\n","    \n","    resultado = transform(image=img, bboxes=bboxes, labels=labels)\n","    img_transformada = resultado[\"image\"]\n","    anotaciones_transformadas = [\n","        [label, *box] for label, box in zip(resultado['labels'], resultado['bboxes']) if box[2] > 0 and box[3] > 0\n","    ]\n","    \n","    return img_transformada, anotaciones_transformadas\n"]},{"cell_type":"code","execution_count":26,"metadata":{"id":"Ov3pCa-NGcFI","executionInfo":{"status":"ok","timestamp":1684596266789,"user_tz":-120,"elapsed":2,"user":{"displayName":"Álvaro Casas Zan","userId":"12446977778724773210"}}},"outputs":[],"source":["def aumentar_dataset(input_folder, output_folder, num_output_images=1000):\n","    transform = A.Compose([\n","        A.Resize(512, 512),\n","        A.HorizontalFlip(p=0.5),\n","        A.VerticalFlip(p=0.5),\n","        A.RandomRotate90(p=0.5),\n","        A.Rotate(limit=10, p=0.5),\n","        A.ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.1, rotate_limit=45, p=0.5),\n","        A.RandomBrightnessContrast(brightness_limit=(-0.1, 0.1), contrast_limit=(0.3, 0.5), p=0.5),\n","        A.HueSaturationValue(hue_shift_limit=20, sat_shift_limit=30, val_shift_limit=20, p=0.5),\n","        A.RandomScale(scale_limit=0.2, p=0.5),\n","        A.GaussNoise(var_limit=(10, 50), mean=0, p=0.5),\n","        A.GaussianBlur(p=0.5),\n","        A.MotionBlur(p=0.5),\n","        A.CLAHE(clip_limit=4.0, p=0.5),\n","        A.Cutout(num_holes=8, max_h_size=16, max_w_size=16, p=0.5),\n","    ], bbox_params=A.BboxParams(format='yolo', label_fields=['labels'], min_area=0.001, min_visibility=0.001))\n","\n","\n","    transform_original = A.Compose([\n","        A.Resize(512, 512)\n","    ], bbox_params=A.BboxParams(format='yolo', label_fields=['labels'], min_area=0.001, min_visibility=0.001))\n","\n","\n","    os.makedirs(output_folder, exist_ok=True)\n","\n","    all_files = os.listdir(input_folder)\n","    img_files = [f for f in all_files if f.endswith(\".jpg\")]\n","    num_files = len(img_files)\n","\n","    for img_name in img_files:\n","        img_path = os.path.join(input_folder, img_name)\n","        txt_path = os.path.join(input_folder, f\"{img_name[:-4]}.txt\")\n","\n","        # Verifica si existe el archivo .txt antes de continuar\n","        if not os.path.exists(txt_path):\n","            continue\n","        \n","        img = cv2.imread(img_path)\n","        anotaciones = leer_anotaciones_yolo(txt_path)\n","\n","        # Aplica la transformación de redimensionamiento a la imagen original y sus anotaciones\n","        img_resized, anotaciones_resized = aplicar_transformacion(img, anotaciones, transform_original)\n","\n","        # Guarda la imagen original redimensionada y su archivo de anotaciones en el directorio de salida\n","        cv2.imwrite(os.path.join(output_folder, img_name), img_resized)\n","        guardar_anotaciones_yolo(anotaciones_resized, os.path.join(output_folder, f\"{img_name[:-4]}.txt\"))\n","       \n","        # Bucle para generar imágenes aumentadas y guardarlas en el directorio de salida\n","        for i in range(num_output_images // num_files):\n","            img_aug, anotaciones_aug = aplicar_transformacion(img, anotaciones, transform)\n","\n","            new_img_name = f\"{img_name[:-4]}_aug_{i}.jpg\"\n","            new_txt_name = f\"{img_name[:-4]}_aug_{i}.txt\"\n","\n","            cv2.imwrite(os.path.join(output_folder, new_img_name), img_aug)\n","            guardar_anotaciones_yolo(anotaciones_aug, os.path.join(output_folder, new_txt_name))"]},{"cell_type":"code","execution_count":27,"metadata":{"id":"3XIZ1wl7GcFJ","executionInfo":{"status":"ok","timestamp":1684596360356,"user_tz":-120,"elapsed":89663,"user":{"displayName":"Álvaro Casas Zan","userId":"12446977778724773210"}}},"outputs":[],"source":["\n","input_folder = \"/content/gdrive/MyDrive/Colab Notebooks/yolov8_grapes-main/datasets/original/train\"\n","output_folder = \"/content/gdrive/MyDrive/Colab Notebooks/yolov8_grapes-main/datasets/augmented/train\"\n","num_output_images = 300\n","\n","aumentar_dataset(input_folder, output_folder, num_output_images)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2gumkVRYGcFK"},"outputs":[],"source":["import cv2\n","import os\n","import albumentations as A\n","\n","def mejorar_brillo_contraste(input_image_path, output_image_path):\n","    # Define la transformación para ajustar el brillo y el contraste de la imagen\n","    transform = A.Compose([\n","        A.RandomBrightnessContrast(brightness_limit=(-0.1, 0.1), contrast_limit=(0.3, 0.5), p=1.0),\n","        A.HueSaturationValue(sat_shift_limit=40, p=1.0),  # Aumenta la diferencia de color\n","        A.ImageCompression(quality_lower=60, quality_upper=100, p=1.0),  # Mejora los detalles de la imagen\n","\n","    ])\n","\n","    # Lee la imagen de entrada\n","    img = cv2.imread(input_image_path)\n","\n","    # Aplica la transformación de brillo y contraste a la imagen\n","    img_transformed = transform(image=img)[\"image\"]\n","\n","    # Guarda la imagen mejorada en el directorio de salida\n","    cv2.imwrite(output_image_path, img_transformed)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_m2Q-YkyGcFL"},"outputs":[],"source":["\n","# Ejemplo de uso de la función:\n","input_folder = \"/content/gdrive/MyDrive/Colab Notebooks/yolov8_grapes-main/datasets/original/test\"\n","output_folder = \"/content/gdrive/MyDrive/Colab Notebooks/yolov8_grapes-main/datasets/augmented/test\"\n","os.makedirs(output_folder, exist_ok=True)\n","\n","all_files = os.listdir(input_folder)\n","img_files = [f for f in all_files if f.endswith(\".jpg\")]\n","\n","for img_name in img_files:\n","    input_image_path = os.path.join(input_folder, img_name)\n","    output_image_path = os.path.join(output_folder, img_name)\n","    mejorar_brillo_contraste(input_image_path, output_image_path)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Hw3oVR51GcFL"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"yolo_env","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.3"},"orig_nbformat":4,"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}